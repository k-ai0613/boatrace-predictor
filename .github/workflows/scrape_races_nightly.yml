name: Scrape Race Data Nightly

on:
  schedule:
    # 毎日深夜3:00（JST）に実行
    # JST 3:00 = UTC 18:00（前日）
    - cron: '0 18 * * *'
  workflow_dispatch:      # 手動実行可能

jobs:
  scrape-races:
    runs-on: ubuntu-latest
    timeout-minutes: 300  # 5時間（余裕を持たせる）

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'

    - name: Install dependencies
      run: |
        pip install -r scraper/requirements.txt

    - name: Resolve IPv4 address for Supabase
      run: |
        # Supabaseのホスト名からIPv4アドレスを取得
        HOST=$(echo "${{ secrets.DATABASE_URL }}" | sed -n 's/.*@\([^:]*\):.*/\1/p')
        echo "Original host: $HOST"

        # IPv4アドレスを解決（digコマンドを使用、AAAAレコードを除外）
        IPV4=$(dig +short -t A "$HOST" | head -n1)
        echo "Resolved IPv4: $IPV4"

        # IPv4アドレスが取得できたか確認
        if [ -z "$IPV4" ]; then
          echo "Error: Failed to resolve IPv4 address"
          exit 1
        fi

        # DATABASE_URLのホスト名をIPv4に置き換え
        DATABASE_URL_IPV4=$(echo "${{ secrets.DATABASE_URL }}" | sed "s/@${HOST}/@${IPV4}/")

        # 環境変数ファイルに保存
        echo "DATABASE_URL_IPV4=$DATABASE_URL_IPV4" >> $GITHUB_ENV

    - name: Run race data scraper
      env:
        DATABASE_URL: ${{ env.DATABASE_URL_IPV4 }}
      run: |
        python scraper/collect_gentle.py --days 7

    - name: Log completion
      run: |
        echo "Race data collected at $(date)" >> race_scrape.log
        git config user.name github-actions
        git config user.email github-actions@github.com
        git add race_scrape.log || exit 0
        git commit -m "Update race scrape log" || exit 0
        git push || exit 0
