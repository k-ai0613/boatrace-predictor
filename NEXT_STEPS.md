# æ¬¡ã«ã™ã¹ãã“ã¨

## âœ… å®Œäº†ã—ãŸã“ã¨

### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åé›†ï¼ˆ2025-11-10 ï½ 2025-11-16ï¼‰
- **æœŸé–“**: 7æ—¥é–“
- **åé›†ãƒ¬ãƒ¼ã‚¹æ•°**: 2,016ãƒ¬ãƒ¼ã‚¹
- **æˆåŠŸç‡**: 100%
- **å¤±æ•—**: 0ä»¶
- **ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹**: kyotei.fun
- **åé›†ãƒ‡ãƒ¼ã‚¿**: ãƒ¬ãƒ¼ã‚¹çµæœã€é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ã€ãƒ¢ãƒ¼ã‚¿ãƒ¼ãƒ»ãƒœãƒ¼ãƒˆæ€§èƒ½ã€æ°—è±¡æ¡ä»¶ãªã©å…¨ã‚«ãƒ©ãƒ 

---

## ğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### 1. ãƒ‡ãƒ¼ã‚¿å“è³ªã®ç¢ºèª âœ¨ **æœ€å„ªå…ˆ**

ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒSupabaseã«æ­£ã—ãä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¾ã™ã€‚

#### ç¢ºèªé …ç›®ï¼š
```sql
-- ãƒ¬ãƒ¼ã‚¹ç·æ•°
SELECT COUNT(*) FROM races WHERE race_date BETWEEN '2025-11-10' AND '2025-11-16';
-- æœŸå¾…å€¤: ç´„2,016ãƒ¬ãƒ¼ã‚¹

-- å‡ºèµ°ã‚¨ãƒ³ãƒˆãƒªç·æ•°
SELECT COUNT(*) FROM race_entries re
JOIN races r ON re.race_id = r.id
WHERE r.race_date BETWEEN '2025-11-10' AND '2025-11-16';
-- æœŸå¾…å€¤: ç´„12,096ã‚¨ãƒ³ãƒˆãƒªï¼ˆ2,016 Ã— 6è‰‡ï¼‰

-- ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¦ã‚«ãƒ©ãƒ ï¼‰
SELECT
  COUNT(*) as total,
  COUNT(racer_grade) as has_grade,
  COUNT(win_rate) as has_win_rate,
  COUNT(motor_rate_2) as has_motor_rate,
  COUNT(boat_rate_2) as has_boat_rate,
  COUNT(result_position) as has_result
FROM race_entries re
JOIN races r ON re.race_id = r.id
WHERE r.race_date BETWEEN '2025-11-10' AND '2025-11-16';
-- æœŸå¾…å€¤: ã™ã¹ã¦ç´„12,096ï¼ˆ100%å®Œå…¨æ€§ï¼‰
```

#### å®Ÿè¡Œæ–¹æ³•ï¼š
```bash
# Supabaseãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§å®Ÿè¡Œ
# ã¾ãŸã¯
python -c "
import os
from dotenv import load_dotenv
import psycopg2

load_dotenv()
conn = psycopg2.connect(os.getenv('DATABASE_URL'))
cursor = conn.cursor()

# ä¸Šè¨˜SQLã‚¯ã‚¨ãƒªã‚’å®Ÿè¡Œ
cursor.execute('SELECT COUNT(*) FROM races WHERE race_date BETWEEN %s AND %s', ('2025-11-10', '2025-11-16'))
print(f'Total races: {cursor.fetchone()[0]}')

conn.close()
"
```

---

### 2. æœ¬ç•ªãƒ‡ãƒ¼ã‚¿åé›†ã®æº–å‚™

ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ãŸã®ã§ã€2.5å¹´åˆ†ã®å…¨ãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿæ–½ã—ã¾ã™ã€‚

#### åé›†ç¯„å›²ï¼š
- **æœŸé–“**: 2023-06-01 ï½ 2025-11-20
- **æ¨å®šãƒ¬ãƒ¼ã‚¹æ•°**: ç´„260,000ãƒ¬ãƒ¼ã‚¹
- **æ¨å®šã‚¨ãƒ³ãƒˆãƒªæ•°**: ç´„1,560,000ã‚¨ãƒ³ãƒˆãƒªï¼ˆ260,000 Ã— 6è‰‡ï¼‰
- **æ¨å®šå®Ÿè¡Œæ™‚é–“**: ç´„72æ™‚é–“ï¼ˆ3æ—¥é–“ï¼‰

#### å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰ï¼š
```bash
cd scraper
python -u collect_historical_data.py \
  --start-date 2023-06-01 \
  --end-date 2025-11-20 \
  --venues 24 \
  --races 12 \
  --delay 2.0 \
  --max-retries 3 \
  > full_collection_log.txt 2>&1 &
```

#### æ¨å¥¨äº‹é …ï¼š
- **æ™‚é–“å¸¯**: ã‚µãƒ¼ãƒãƒ¼è² è·ãŒä½ã„æ·±å¤œãƒ»æ—©æœã«é–‹å§‹
- **ç›£è¦–**: å®šæœŸçš„ã«é€²æ—ç¢ºèªï¼ˆ`tail -f scraper/full_collection_log.txt`ï¼‰
- **ä¸­æ–­å¯¾ç­–**: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼ˆä¸Šè¨˜ã‚³ãƒãƒ³ãƒ‰ã®`&`ï¼‰ã§ç«¯æœ«ã‚’é–‰ã˜ã¦ã‚‚ç¶™ç¶š

---

### 3. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°

ãƒ‡ãƒ¼ã‚¿åé›†å®Œäº†å¾Œã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¾ã™ã€‚

#### æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ï¼š
- `ml/train_model.py` - åŸºæœ¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´
- `ml/train_full_pipeline.py` - ãƒ•ãƒ«ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- `ml/hyperparameter_tuning.py` - ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–

#### å®Ÿè¡Œæ‰‹é †ï¼š
```bash
# 1. çµ±è¨ˆçš„ç‰¹å¾´é‡ã®ç”Ÿæˆ
python ml/advanced_stats.py

# 2. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
python ml/train_full_pipeline.py

# 3. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
python ml/hyperparameter_tuning.py

# 4. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
python ml/evaluate_model.py
```

---

### 4. äºˆæ¸¬APIã®æ”¹å–„

ç¾åœ¨ã®äºˆæ¸¬APIã«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã—ã¾ã™ã€‚

#### ä¿®æ­£ãƒ•ã‚¡ã‚¤ãƒ«ï¼š
- `app/api/predict/route.ts`
- `lib/predictions.ts`

#### å®Ÿè£…å†…å®¹ï¼š
- ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ï¼ˆ`.pkl`ï¼‰ã®ãƒ­ãƒ¼ãƒ‰
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- äºˆæ¸¬ç²¾åº¦ã®è¡¨ç¤º

---

### 5. åˆ†æãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã®æ´»ç”¨

æ—¢ã«å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§åé›†ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚

#### åˆ©ç”¨å¯èƒ½ãªæ©Ÿèƒ½ï¼š
- `app/analytics/` - ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ãƒšãƒ¼ã‚¸
- `components/analytics/` - çµ±è¨ˆã‚°ãƒ©ãƒ•ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- `lib/analytics.ts` - çµ±è¨ˆè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯

#### ç¢ºèªURLï¼š
```
http://localhost:3000/analytics
```

---

## ğŸš¨ æ³¨æ„äº‹é …

### ãƒ‡ãƒ¼ã‚¿åé›†æ™‚ã®æ³¨æ„ï¼š
1. **ã‚µãƒ¼ãƒãƒ¼è² è·**: `--delay 2.0`ï¼ˆ2ç§’é–“éš”ï¼‰ã‚’ç¶­æŒ
2. **ã‚¨ãƒ©ãƒ¼ç›£è¦–**: ãƒ­ã‚°ã§`Failed`ã‚„`Error`ã‚’å®šæœŸç¢ºèª
3. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å®¹é‡**: Supabaseã®å®¹é‡åˆ¶é™ã«æ³¨æ„ï¼ˆç´„1.5GBå¿…è¦ï¼‰
4. **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: å®‰å®šã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…é ˆ

### æ¬¡å›ä»¥é™ã®å®šæœŸåé›†ï¼š
- **GitHub Actions**: `.github/workflows/daily-data-collection.yml`ã‚’ä½¿ç”¨
- **è‡ªå‹•å®Ÿè¡Œ**: æ¯æ—¥æ·±å¤œã«å‰æ—¥åˆ†ã‚’è‡ªå‹•åé›†
- **æ‰‹å‹•å®Ÿè¡Œ**: å¿…è¦ã«å¿œã˜ã¦`workflow_dispatch`ã§æ‰‹å‹•ãƒˆãƒªã‚¬ãƒ¼

---

## ğŸ“Š æœŸå¾…ã•ã‚Œã‚‹æˆæœ

### ãƒ‡ãƒ¼ã‚¿å“è³ªï¼š
- âœ… 100%ã®æˆåŠŸç‡ï¼ˆãƒ†ã‚¹ãƒˆã§å®Ÿè¨¼æ¸ˆã¿ï¼‰
- âœ… å…¨ã‚«ãƒ©ãƒ ã®å®Œå…¨æ€§ï¼ˆracer_grade, win_rate, motor_rateç­‰ï¼‰
- âœ… 2.5å¹´åˆ†ã®æ­´å²ãƒ‡ãƒ¼ã‚¿ï¼ˆç´„156ä¸‡ã‚¨ãƒ³ãƒˆãƒªï¼‰

### äºˆæ¸¬ç²¾åº¦å‘ä¸Šï¼š
- ç¾åœ¨ï¼šåŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿ã®ã¿
- æ”¹å–„å¾Œï¼šé¸æ‰‹ç´šåˆ¥ã€ãƒ¢ãƒ¼ã‚¿ãƒ¼æ€§èƒ½ã€ãƒœãƒ¼ãƒˆæ€§èƒ½ã€STã‚¿ã‚¤ãƒŸãƒ³ã‚°ã€å±•ç¤ºãƒ‡ãƒ¼ã‚¿ç­‰ã‚’å«ã‚€
- æœŸå¾…ç²¾åº¦ï¼š70-80%ä»¥ä¸Šï¼ˆ3é€£å˜çš„ä¸­ç‡ï¼‰

---

## ğŸ”„ æ¨å¥¨å®Ÿè¡Œé †åº

```
1. ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèªï¼ˆä¸Šè¨˜SQLå®Ÿè¡Œï¼‰ â†’ 10åˆ†
2. æœ¬ç•ªãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ â†’ 72æ™‚é–“ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰
3. åé›†å®Œäº†ç¢ºèª â†’ 10åˆ†
4. çµ±è¨ˆçš„ç‰¹å¾´é‡ç”Ÿæˆ â†’ 30åˆ†
5. ãƒ¢ãƒ‡ãƒ«è¨“ç·´ â†’ 2-3æ™‚é–“
6. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ â†’ 10åˆ†
7. äºˆæ¸¬APIçµ±åˆ â†’ 1æ™‚é–“
8. å‹•ä½œç¢ºèªãƒ»ãƒ†ã‚¹ãƒˆ â†’ 30åˆ†
```

**ç·æ‰€è¦æ™‚é–“**: ç´„3æ—¥é–“ï¼ˆãã®ã†ã¡æ‰‹ä½œæ¥­ã¯ç´„3-4æ™‚é–“ï¼‰

---

## ğŸ“ ã‚³ãƒãƒ³ãƒ‰ã¾ã¨ã‚

### ãƒ‡ãƒ¼ã‚¿å“è³ªç¢ºèªï¼š
```bash
cd scraper
python -c "
import os
from dotenv import load_dotenv
import psycopg2

load_dotenv()
conn = psycopg2.connect(os.getenv('DATABASE_URL'))
cursor = conn.cursor()

cursor.execute('SELECT COUNT(*) FROM races WHERE race_date BETWEEN %s AND %s', ('2025-11-10', '2025-11-16'))
print(f'Total races: {cursor.fetchone()[0]}')

cursor.execute('''
SELECT
  COUNT(*) as total,
  COUNT(racer_grade) as has_grade,
  COUNT(win_rate) as has_win_rate,
  COUNT(motor_rate_2) as has_motor_rate,
  COUNT(boat_rate_2) as has_boat_rate,
  COUNT(result_position) as has_result
FROM race_entries re
JOIN races r ON re.race_id = r.id
WHERE r.race_date BETWEEN %s AND %s
''', ('2025-11-10', '2025-11-16'))
result = cursor.fetchone()
print(f'Total entries: {result[0]}')
print(f'Has grade: {result[1]} ({result[1]*100/result[0]:.1f}%)')
print(f'Has win_rate: {result[2]} ({result[2]*100/result[0]:.1f}%)')
print(f'Has motor_rate: {result[3]} ({result[3]*100/result[0]:.1f}%)')
print(f'Has boat_rate: {result[4]} ({result[4]*100/result[0]:.1f}%)')
print(f'Has result: {result[5]} ({result[5]*100/result[0]:.1f}%)')

conn.close()
"
```

### æœ¬ç•ªãƒ‡ãƒ¼ã‚¿åé›†ï¼š
```bash
cd scraper
nohup python -u collect_historical_data.py \
  --start-date 2023-06-01 \
  --end-date 2025-11-20 \
  --venues 24 \
  --races 12 \
  --delay 2.0 \
  --max-retries 3 \
  > full_collection_log.txt 2>&1 &

# é€²æ—ç¢ºèª
tail -f scraper/full_collection_log.txt
```

### æ©Ÿæ¢°å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼š
```bash
python ml/advanced_stats.py
python ml/train_full_pipeline.py
python ml/evaluate_model.py
```

---

#12
